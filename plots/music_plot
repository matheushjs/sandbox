#!/usr/bin/python3 -i

import os, sys
import matplotlib.pyplot as plt
import numpy as np
import subprocess as sp
import tempfile
import shutil
import json

# Refer to https://github.com/jiaaro/pydub/blob/master/API.markdown for the API documentation
from pydub import AudioSegment

# TODO: Allow the user to have more control over ffmpeg (output format & c:a for example)

SUPPORTED_FORMATS = ["mp3", "wma", "m4a", "aac", "wav", "aiff", "flac", "ogg", "oga", "webm"]

usageStr = \
"""
Usage: {} [options] input_file1 [input_file2 ...]

By default this program will just output useful information about the song given as argument.

Options
    -h                Displays this help message.
    --dir             All files in the current directory will be processed
    --rms [float]     The RMS level (in dB) to which we should normalize the song.
""".format(sys.argv[0])

# Stores arguments passed via command line
cmdArgs = dict()

def parse_arguments():
    if "-h" in sys.argv or len(sys.argv) == 1:
        print(usageStr)
        sys.exit(0)

    # Remove program name
    sys.argv = sys.argv[1:]

    for (cmd, TYP) in [
                        ("--rms", float),
                        ("--dir", str),
                        ]:
        if cmd in sys.argv:
            try:
                idx = sys.argv.index(cmd)
                val = TYP(sys.argv[idx + 1])
                cmdArgs[cmd] = val
            except Exception as e:
                print("Error parsing argument {} : {}!".format(cmd, e))
                sys.exit(1)
            sys.argv.remove(cmd)

    if "--dir" in cmdArgs:
        if os.path.exists(cmdArgs["--dir"]) is False:
            print("Given directory path does not exist!")
            sys.exit(1)

    if "--dir" not in cmdArgs:
        cmdArgs["ifiles"] = sys.argv # Everything left is input filenames
        cmdArgs["iexts"]  = [ fil.split(".")[-1] for fil in cmdArgs["ifiles"] ] # Extensions of input files

    if "--rms" in cmdArgs:
        cmdArgs["--rms"] = -abs(cmdArgs["--rms"])
    else:
        cmdArgs["--rms"] = -10.0

# Just a wrapper to allow us more flexibility
def myprint(*args, **kwargs):
    print(*args, **kwargs)

class MyAudio:
    def __init__(self, ifile, ext, gain=None):
        self.ifile = ifile
        self.ext   = ext

        # Read the file
        try:
            self.audio = AudioSegment.from_file(ifile, iext)
            self.audio.set_channels(2) # force 2 channels
        except Exception as e:
            raise(Exception("Audio format not supported. ({})".format(e)))

        if gain:
            self.audio = self.audio.apply_gain(gain)

        self.rms                    = self.audio.rms
        self.sample_width           = self.audio.sample_width
        self.max                    = self.audio.max
        self.max_dBFS               = self.audio.max_dBFS
        self.max_possible_amplitude = self.audio.max_possible_amplitude
        self.channels               = self.audio.channels
        self.frame_count            = self.audio.frame_count
        self.frame_rate             = self.audio.frame_rate
        self.frame_width            = self.audio.frame_width
        self.dBFS                   = self.audio.dBFS
        self.duration_seconds       = self.audio.duration_seconds

        self.samples = np.frombuffer(self.audio.raw_data, dtype=np.int16) # assume signed 16 bit
        self.nSamples = self.samples.shape[0]
        self.samples = self.samples.reshape(self.nSamples//2, 2, order="C") # assume 2 channels, reshape the array to 2 columns

        # Attention to the useful methods of 'audio'!
        #
        # audio.rms              audio.append(     audio.low_pass_filter(      audio.high_pass_filter(      audio.sample_width
        # audio.apply_gain(      audio.max         audio.max_dBFS              audio.max_possible_amplitude audio.array_type
        # audio.channels         audio.frame_count audio.get_array_of_samples  audio.frame_rate             audio.get_dc_offset(
        # audio.frame_width      audio.get_frame(  audio.raw_data              audio.dBFS                   audio.from_file(
        # audio.duration_seconds audio.reverse(    audio.set_channels(

    # Square root of the mean of the square of each sample https://en.wikipedia.org/wiki/Root_mean_square
    # NOTE: A nice strategy could be calculate rms over all 1- or 5-second windows, and let the rms be the maximum one
    def my_rms(self, p=4):
        # Below gave nice results too. Could investigate it further
        # powers = 20*np.log10(np.abs(samples, dtype=np.float64) + 1)
        # powers = np.power(powers * (np.max(samples) / np.max(powers)), 2, dtype=np.float64)

        windowSize = round(self.frame_rate * self.channels * 0.4) # 0.4 seconds
        myprint("No. Windows:", self.samples.size // windowSize)

        # If there are less than 10 windows, do the usual normalization
        if self.samples.size / windowSize < 10:
            powers = np.power(self.samples, p, dtype=np.float64)
        else:
            # Else downsample the song by max-pooling each window
            # TODO: We must use some overlapping here.
            powers = self.samples.ravel()
            # Discard some samples so that it is evenly divided
            powers = powers[0:len(powers) - len(powers)%windowSize]
            powers = np.max(np.abs(powers.reshape(-1, windowSize)), axis=1)
            powers = np.power(powers, p, dtype=np.float64)

        if np.sum(powers < 0) > 0:
            raise(Exception("Numeric overflow detected."))

        return np.power(np.mean(powers), 1/p)

    # Checks if the given audio is normalized based on a max-possible-amplitude normalization
    # We use a 10% tolerance from a perfect normalization)
    #
    # @return True if the given audio is normalized, False otherwise.
    def is_normalized(self):
        fraction = self.max / self.max_possible_amplitude
        return False if fraction < 0.9 else True

    def apply_gain(self, gain):
        return MyAudio(self.ifile, self.ext, gain)

def process_file(ifile, iext):
    audio = MyAudio(ifile, iext)

    myprint("Frame rate:", audio.frame_rate)
    myprint("Channels:", audio.channels)

    # Refer to https://en.wikipedia.org/wiki/DBFS (DeciBels relative to Full Scale)
    # Also see https://en.wikipedia.org/wiki/Decibel for the formula
    # 10*log10(P / P_0) where P_0 is the reference value (max power)
    # 20*log10(A / A_0) where A_0 is the max amplitude (see the source code of pydub)
    myprint("Max dBFS:", audio.max_dBFS)

    def to_db(value, maxValue):
        return 20 * np.log10(value / maxValue)

    def from_db(valueDb, maxValue):
        return np.power(10, valueDb/20) * maxValue

    # We use the property RMS(a*X) = a*RMS(X)
    def get_rms_normalization_factor(rmsValue, maxValue, normLevelDb=-17):
        normLevel = from_db(normLevelDb, maxValue)
        return normLevel / rmsValue

    myprint("Max-amplitude Normalized:", audio.is_normalized())

    rms = audio.my_rms()
    myprint("RMS:", to_db(rms, audio.max_possible_amplitude), "dB")

    factor = float(get_rms_normalization_factor(rms, audio.max_possible_amplitude, cmdArgs["--rms"]))
    myprint("Gain: {:.5f} x".format(factor))

    # In the original audio, samples large than 'clippingBound' will be clipped
    clippingBound = audio.max_possible_amplitude / factor

    # We need to preserve the values even if they are clipped, so we increase precision
    normalized = audio.samples.astype(np.int32, copy=True)
    normalized.dtype = np.int32 # Was int16

    # Calculate number of clipped samples
    idx = np.abs(normalized) > clippingBound
    clipCount = np.sum(idx)

    if clipCount > 0:
        myprint("Samples_Clipped: {} ({:.5f}%)".format(clipCount, clipCount / len(audio.samples) * 100))

    # Calculate gain
    normalized = normalized * factor
    normalizedMax = np.max(np.abs( [normalized.max(), normalized.min()] ))
    gainDb = to_db(normalizedMax, audio.max) # NOTE: if normalizedMax is clipped, this will be wrong!
    myprint("Gain:", gainDb, "dB")

    # Effectively normalize the song
    normalizedAudio = audio.apply_gain(gainDb)

    myprint("New_Maximum_dBFS:", to_db(np.max(np.abs(normalized)), audio.max_possible_amplitude), "dB")
    myprint("New_RMS:", to_db(normalizedAudio.my_rms(), normalizedAudio.max_possible_amplitude), "dB")

    #plt.figure(dpi=150)
    #plt.title("Changes made to the song (just a fraction of the song)")
    #if factor < 1:
    #    plt.plot(samples[:100000,0], c="blue", label="Old")
    #    plt.plot(normalized[:100000,0], c="red", label="New")
    #else:
    #    plt.plot(normalized[:100000,0], c="red", label="New")
    #    plt.plot(samples[:100000,0], c="blue", label="Old")
    #
    #plt.legend()
    #plt.show()

    #mat = np.zeros((yResolution, songLen))
    #for i in range(songLen):
    #    idx = samples[i, 0]

    #plt.figure(figsize=(12, 6))
    #plt.imshow(mat)
    #plt.show()
    #plt.plot(np.arange(samples.shape[0]), samples[:,0], c="#0000FF77")
    #plt.show()

    return (audio, normalizedAudio)

##########################
#     MAIN CODE          #
##########################

parse_arguments()
print(cmdArgs)

allFiles = cmdArgs["ifiles"]
nFiles = len(allFiles)

debugInfo = {
            "exceptions": [],
            "failedFiles": []
        }

# Will hold audio data for all audio files given on command line
allSamples = []
allNormalized = []

for idx, (ifile, iext) in enumerate(zip(allFiles, cmdArgs["iexts"])):
    print("({}/{}) Processing file '{}' ".format(idx+1, nFiles, ifile))

    try:
        before, normalized = process_file(ifile, iext)
        allSamples.append(before)
        allNormalized.append(normalized)
    except Exception as e:
        print("Exception on file {}: {}".format(ifile, e))
        debugInfo["exceptions"].append(str(e))
        debugInfo["failedFiles"].append(ifile)

if len(debugInfo["exceptions"]) > 0:
    print("Debug information being dumped to 'elf-normalize.out'")
    with open("elf-normalize.out", "w") as fp:
        json.dump(debugInfo, fp, indent=2)

plt.figure(figsize=(9, 9))

curOffset = 0
for samp, norm in zip(allSamples, allNormalized):
    seq = np.arange(samp.samples.shape[0]) + curOffset
    line1, = plt.plot(seq, norm.samples[:,0], c="#0000FF77")
    line2, = plt.plot(seq, samp.samples[:,0], c="darkred")
    curOffset += samp.samples.shape[0]

line1.set_label("After Norm")
line2.set_label("Before Norm")
plt.tight_layout()
plt.ylim(-38000, +38000)
plt.legend()
plt.show()

n = allNormalized[0].audio
for m in allNormalized[1:]:
    n = n + m.audio
n.export(open("normalized.wav", "wb"), format="wav")
